<!DOCTYPE html>
<html lang="en"><head>
<script src="mpg6_files/libs/clipboard/clipboard.min.js"></script>
<script src="mpg6_files/libs/quarto-html/tabby.min.js"></script>
<script src="mpg6_files/libs/quarto-html/popper.min.js"></script>
<script src="mpg6_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="mpg6_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="mpg6_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="mpg6_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="mpg6_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <meta name="author" content="Sarah Urbut, MD PhD">
  <meta name="dcterms.date" content="2025-03-29">
  <title>A Practical Primer on Bayesian Statistics</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="mpg6_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="mpg6_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #24292e;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #24292e; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #d73a49; } /* Attribute */
    code span.bn { color: #005cc5; } /* BaseN */
    code span.bu { color: #d73a49; } /* BuiltIn */
    code span.cf { color: #d73a49; } /* ControlFlow */
    code span.ch { color: #032f62; } /* Char */
    code span.cn { color: #005cc5; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #d73a49; } /* DataType */
    code span.dv { color: #005cc5; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #d73a49; font-weight: bold; } /* Extension */
    code span.fl { color: #005cc5; } /* Float */
    code span.fu { color: #6f42c1; } /* Function */
    code span.im { color: #032f62; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #d73a49; } /* Keyword */
    code span.op { color: #24292e; } /* Operator */
    code span.ot { color: #6f42c1; } /* Other */
    code span.pp { color: #d73a49; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #005cc5; } /* SpecialChar */
    code span.ss { color: #032f62; } /* SpecialString */
    code span.st { color: #032f62; } /* String */
    code span.va { color: #e36209; } /* Variable */
    code span.vs { color: #032f62; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
  </style>
  <link rel="stylesheet" href="mpg6_files/libs/revealjs/dist/theme/quarto.css">
  <link href="mpg6_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="mpg6_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="mpg6_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="mpg6_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">A Practical Primer on Bayesian Statistics</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Sarah Urbut, MD PhD 
</div>
</div>
</div>

  <p class="date">2025-03-29</p>
</section>
<section id="overview" class="slide level2">
<h2>Overview</h2>
<p>In this seminar, we’ll (attempt to) cover key Bayesian concepts critical for modern genomics:</p>
<ol type="1">
<li><strong>P-values vs.&nbsp;Posterior Probabilities</strong>: Why Bayesian thinking helps avoid misinterpretations<br>
</li>
<li><strong>Conjugate Models</strong>: Elegant solutions for population genetic inference<br>
</li>
<li><strong>Mixture Models</strong>: Powerful tools for complex genomic data<br>
</li>
<li><strong>Bayesian Clinical &amp; Adaptive Designs</strong>: Learning and adapting as data accumulates</li>
</ol>
</section>
<section>
<section id="the-p-value-paradox" class="title-slide slide level1 center">
<h1>1. The P-value Paradox</h1>

</section>
<section id="lindleys-paradox" class="slide level2">
<h2>Lindley’s Paradox</h2>
<blockquote>
<p>“A result that is statistically significant may not be scientifically significant” - Dennis Lindley (1957)</p>
</blockquote>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>Lindley’s 1957 paper demonstrated how p-values and Bayes factors can lead to contradictory conclusions <span class="citation" data-cites="lindley1957">[@lindley1957]</span></p>
</div>
</div>
</div>
</section>
<section id="the-evidence-paradox" class="slide level2">
<h2>The Evidence Paradox</h2>
<p>Sometimes a result can be unlikely under the null hypothesis but even more unlikely under the alternative!</p>
</section>
<section id="example" class="slide level2">
<h2>Example</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-1-1.png" width="960" class="r-stretch"><aside class="notes">
<p>This paradox shows why we need to consider both the null and alternative hypotheses: - A small p-value only tells us the result is unlikely under <span class="math inline">\(H_0\)</span> - But for real evidence, we need the result to be more likely under <span class="math inline">\(H_1\)</span> than <span class="math inline">\(H_0\)</span> - This is why Bayes factors (likelihood ratios) are more informative than p-values</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-p-value-fallacy" class="slide level2">
<h2>The P-value Fallacy</h2>
<p>What we want: P(Hypothesis|Data)<br>
What we get: P(Data|Null Hypothesis)</p>
<p>Question for the class: What is a P value?</p>
<p>Prepare to be amazed: Frequentists are all Bayesians! (under some qualifications)</p>
</section>
<section id="probabilistic-interpretation-of-estimates" class="slide level2">
<h2>Probabilistic Interpretation of Estimates</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>In the Bayesian framework:</p>
<ul>
<li><strong>Parameters are random variables</strong> with distributions, not fixed values</li>
<li><strong>Uncertainty is represented directly</strong> through probability distributions</li>
<li><strong>All evidence is integrated coherently</strong> within a probability framework</li>
<li><strong>Natural quantification of uncertainty</strong> <em>without</em> hypothetical repeated sampling</li>
<li><strong>Interpretation is direct and intuitive</strong> for researchers and clinicians</li>
</ul>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="mpg6_files/figure-revealjs/unnamed-chunk-2-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="bayesian-vs.-frequentist-intervals" class="slide level2">
<h2>Bayesian vs.&nbsp;Frequentist Intervals</h2>
<table class="caption-top">
<colgroup>
<col style="width: 47%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th>Bayesian Credible Interval</th>
<th>Frequentist Confidence Interval</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>“95% probability the parameter is between a and b”</td>
<td>“If we repeated the experiment many times, 95% of intervals constructed would contain the true parameter”</td>
</tr>
<tr class="even">
<td>Directly interpretable as probability statement about the parameter</td>
<td>Cannot be interpreted as probability statement about the parameter</td>
</tr>
<tr class="odd">
<td>Incorporates prior information</td>
<td>No mechanism to incorporate prior information (why would you run?)</td>
</tr>
<tr class="even">
<td>Can be asymmetric, reflecting asymmetric uncertainty</td>
<td>Typically symmetric by construction</td>
</tr>
<tr class="odd">
<td>Conditioning on the observed data</td>
<td>Based on hypothetical repeated (theoretical) sampling</td>
</tr>
</tbody>
</table>
</section>
<section id="bayes-theorem---the-core-idea" class="slide level2">
<h2>Bayes’ Theorem - The Core Idea</h2>
<p><span class="math display">\[P(H|D) = \frac{P(D|H) \times P(H)}{P(D)}\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(P(H|D)\)</span> is the <strong>posterior probability</strong> - what we want to know</li>
<li><span class="math inline">\(P(D|H)\)</span> is the <strong>likelihood</strong> - how probable the data is under our hypothesis</li>
<li><span class="math inline">\(P(H)\)</span> is the <strong>prior probability</strong> - what we knew before</li>
<li><span class="math inline">\(P(D)\)</span> is the <strong>evidence</strong> - a normalizing constant</li>
</ul>
<p>Simply: <strong>Posterior ∝ Likelihood × Prior</strong></p>
</section>
<section id="bayesian-updating-visual-intuition" class="slide level2">
<h2>Bayesian Updating: Visual Intuition</h2>

<img data-src="mpg6_files/figure-revealjs/bayesian-updating-1.png" width="960" class="r-stretch"></section></section>
<section>
<section id="p-values-vs.-posterior-probabilities" class="title-slide slide level1 center">
<h1>P-values vs.&nbsp;Posterior Probabilities</h1>

</section>
<section id="the-question" class="slide level2">
<h2>The Question</h2>
<p>As scientists, we want to know:</p>
<blockquote>
<p>“What is the probability that my hypothesis is true, given my data?”</p>
</blockquote>
<p>But traditional p-values answer a different question:</p>
<blockquote>
<p>“What is the probability of observing data this extreme or more extreme, if the null hypothesis is true?”</p>
</blockquote>
<p>This mismatch causes persistent misinterpretations.</p>
</section>
<section id="p-values-vs.-bayes-factors-definitions" class="slide level2">
<h2>P-values vs.&nbsp;Bayes Factors: Definitions</h2>
<p><strong>P-value</strong>:<br>
- <span class="math inline">\(P(data|H_0)\)</span> - probability of data given null hypothesis<br>
- Measures compatibility of data with null hypothesis<br>
- Does not directly measure evidence for alternative</p>
<p><strong>Bayes Factor</strong>:<br>
- <span class="math inline">\(BF_{10} = \frac{P(data|H_1)}{P(data|H_0)}\)</span> - ratio of likelihoods</p>
<p>- <span class="math inline">\(BF_{01} = \frac{P(data|H_0)}{P(data|H_1)}\)</span> - ratio of likelihoods<br>
- Directly compares evidence for alternative vs.&nbsp;null OR null vs alternative<br>
- Tells you how much to update your beliefs</p>
</section>
<section id="the-p-value-fallacy-1" class="slide level2">
<h2>The P-value Fallacy</h2>
<p><strong>Scenario</strong>: Testing a SNP for disease association</p>
<p><strong>Traditional approach</strong>:<br>
- Obtain p = 0.001<br>
- Declare “significant association”<br>
- Publish result</p>
<p><strong>The fallacy</strong>:<br>
- p = 0.001 means “1 in 1000 chance of seeing this data if no association exists”<br>
- NOT “999 in 1000 chance the association is real”</p>
</section>
<section id="visualize" class="slide level2">
<h2>Visualize</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-3-1.png" width="960" class="r-stretch"><p><strong>Key insight</strong>: With a realistic prior of 1/1000, a “significant” p-value of 0.001 only gives ~18% posterior probability of true association! (app interlude) <a href="https://surbut.shinyapps.io/shinypval/">Shiny P!</a></p>
</section>
<section id="the-mathematical-connection" class="slide level2">
<h2>The Mathematical Connection</h2>
<p>Under certain conditions, p-values can be converted to minimum Bayes factors:</p>
<p><span class="math display">\[BF_{min} ≈ -e \times p \times \log(p)\]</span></p>
<p>Meaning even the most favorable interpretation of a p-value provides less evidence than typically assumed:</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>p-value</th>
<th>Minimum Bayes Factor</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.05</td>
<td>0.37</td>
</tr>
<tr class="even">
<td>0.01</td>
<td>0.084</td>
</tr>
<tr class="odd">
<td>0.001</td>
<td>0.0083</td>
</tr>
</tbody>
</table>
</section>
<section id="what-is-the-minimum-bayes-factor" class="slide level2">
<h2>What is the Minimum Bayes Factor?</h2>
<p>The Minimum Bayes Factor is calculated as:<br>
<span class="math inline">\(\text{MBF} \approx -e \times p \times \log(p)\)</span></p>
<p>This formula (derived by Sellke, Bayarri, and Berger) represents the <strong>smallest possible Bayes factor</strong> that could correspond to a given p-value, regardless of the specific alternative hypothesis being tested (i.e p(D|H0)/p(D/H1))</p>
</section>
<section id="why-minimum" class="slide level2">
<h2>Why “Minimum”?</h2>
<p>It’s called “minimum” because:</p>
<ul>
<li>It assumes the most favorable conditions for the alternative hypothesis<br>
</li>
<li>It represents the strongest possible evidence against the null that could be derived from a p-value<br>
</li>
<li>It’s the smallest value the Bayes factor could take (stronger evidence against null = smaller Bayes factor)</li>
</ul>
</section>
<section id="interpretation" class="slide level2">
<h2>Interpretation</h2>
<p>The MBF represents the ratio of likelihoods:<br>
<span class="math inline">\(\text{MBF} = \frac{P(\text{data}|H_0)}{P(\text{data}|H_1)}\)</span></p>
<p>For example, with p = 0.05: MBF = 0.37 This means the data are at most 1/0.37 ≈ 2.7 times more likely under the alternative than the null<br>
Even with the most optimistic assumptions, the evidence against the null is modest</p>
</section>
<section id="why-this-conversion-matters" class="slide level2">
<h2>Why This Conversion Matters</h2>
<p>This conversion from p-values to MBF is important because:</p>
<ul>
<li>It provides a more calibrated interpretation of statistical evidence<br>
</li>
<li>It shows that conventional “statistical significance” (p &lt; 0.05) actually represents fairly modest evidence<br>
</li>
<li>It helps researchers avoid overinterpreting p-values<br>
</li>
<li>It establishes a link between frequentist and Bayesian approaches</li>
</ul>
</section>
<section id="p-values-systematically-overstate-the-evidence-against-the-null-hypothesis." class="slide level2">
<h2>p-values systematically overstate the evidence against the null hypothesis.</h2>
<p>When converted to the Bayes factor scale, even a seemingly impressive p-value often translates to much more moderate evidence against the null hypothesis than most researchers would expect.</p>
</section>
<section id="p-values-vs.-bayes-factors-in-genomics" class="slide level2">
<h2>P-values vs.&nbsp;Bayes Factors in Genomics</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-4-1.png" width="960" class="r-stretch"><p>The GWAS significance threshold of p &lt; 5×10⁻⁸ corresponds to much stronger evidence than p = 0.05.</p>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>Berger and Sellke (1987) showed that p-values systematically overstate evidence against the null <span class="citation" data-cites="berger1987">[@berger1987]</span></p>
</div>
</div>
</div>
</section>
<section id="interpreting-bayes-factors" class="slide level2">
<h2>Interpreting Bayes Factors</h2>
<p>Bayes factors have a natural interpretation:</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Bayes Factor (<span class="math inline">\(BF_{10}\)</span>)</th>
<th>Evidence for H1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1 - 3</td>
<td>Barely worth mentioning</td>
</tr>
<tr class="even">
<td>3 - 10</td>
<td>Substantial</td>
</tr>
<tr class="odd">
<td>10 - 30</td>
<td>Strong</td>
</tr>
<tr class="even">
<td>30 - 100</td>
<td>Very strong</td>
</tr>
<tr class="odd">
<td>&gt; 100</td>
<td>Extreme</td>
</tr>
</tbody>
</table>
<p>A <span class="math inline">\(BF_{10} = 10\)</span> means the data are 10 times more likely under H1 than H0.</p>
</section>
<section id="from-bayes-factor-to-posterior-probability" class="slide level2">
<h2>From Bayes Factor to Posterior Probability</h2>
<p>Bayes’ theorem connects all the pieces:</p>
<p><span class="math display">\[P(H_1|data) = \frac{P(data|H_1)P(H_1)}{P(data|H_1)P(H_1) + P(data|H_0)P(H_0)}\]</span></p>
<p>This can be rewritten using the Bayes factor:</p>
<p><span class="math display">\[P(H_1|data) = \frac{BF_{10} \times P(H_1)}{BF_{10} \times P(H_1) + P(H_0)}\]</span></p>
</section>
<section id="posterior-odds-formulation" class="slide level2">
<h2>Posterior Odds Formulation</h2>
<p>A simplified version:</p>
<p><span class="math display">\[\text{Posterior Odds} = \text{Bayes Factor} \times \text{Prior Odds}\]</span></p>
<p>Or:</p>
<p><span class="math display">\[\frac{P(H_1|data)}{P(H_0|data)} = BF_{10} \times \frac{P(H_1)}{P(H_0)}\]</span></p>
<p>This clearly shows how Bayes factors calibrate our prior beliefs (and we can use this on the wards!).</p>
</section>
<section id="benefits-of-bayes-factors-for-genomics" class="slide level2">
<h2>Benefits of Bayes Factors for Genomics</h2>
<ol type="1">
<li><strong>Calibrated evidence</strong>: Direct measure of evidence strength<br>
</li>
<li><strong>Multiple testing</strong>: Naturally incorporates prior odds<br>
</li>
<li><strong>Replication</strong>: Coherent framework for combining evidence across studies<br>
</li>
<li><strong>Diverse hypotheses</strong>: Can compare non-nested models<br>
</li>
<li><strong>Positive evidence</strong>: Can support null hypothesis, not just reject it<br>
</li>
<li><strong>Study design</strong>: Allows stopping when evidence is sufficient</li>
</ol>
</section>
<section id="key-takeaways" class="slide level2">
<h2>Key Takeaways</h2>
<ol type="1">
<li>P-values answer a different question than most scientists ask<br>
</li>
<li>Bayes factors directly compare competing hypotheses<br>
</li>
<li>Even “significant” p-values provide weaker evidence than typically assumed<br>
</li>
<li>Bayes factors have a natural interpretation as evidence strength<br>
</li>
<li>Converting to posterior probabilities requires considering prior odds<br>
</li>
<li>In genomics, this perspective helps manage false discovery rates</li>
</ol>
</section>
<section id="the-fallacy-of-p-values" class="slide level2">
<h2>The Fallacy of P-values</h2>
<div>
<ul>
<li class="fragment"><p>P-values answer a <strong>counterfactual question</strong>: “If there were no effect, how surprising would these data be?”</p></li>
<li class="fragment"><p>But researchers want to know: “<strong>What is the probability this association is real?</strong>”</p></li>
<li class="fragment"><p>This disconnect leads to systematic misinterpretation</p></li>
</ul>
</div>
</section>
<section id="the-multiple-testing-challenge" class="slide level2">
<h2>2. The Multiple Testing Challenge</h2>
<p>Modern genomics routinely tests <strong>thousands to millions</strong> of hypotheses:</p>
<ul>
<li>20,000+ genes in differential expression<br>
</li>
<li>Millions of variants in GWAS<br>
</li>
<li>Billions of potential interactions</li>
</ul>
<p><strong>The consequence</strong>: Many “significant” findings are actually false positives.</p>
</section>
<section id="the-traditional-approach" class="slide level2">
<h2>The Traditional Approach</h2>
<p>When testing m hypotheses at significance level α:</p>
<ul>
<li>Expected number of false positives: m × α<br>
</li>
<li>With m = 1,000,000 and α = 0.05: <strong>50,000 false positives!</strong></li>
</ul>
<p><strong>Frequentist solutions</strong>:<br>
- Bonferroni correction: α/m<br>
- False Discovery Rate (FDR) control (Benjamini-Hochberg)<br>
- Family-wise error rate (FWER) control (Drawing time)?)</p>
</section>
<section id="visualizing-multiple-hypothesis-testing" class="slide level2">
<h2>Visualizing Multiple Hypothesis Testing</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-5-1.png" width="960" class="r-stretch"><p>The challenge: Separating true signals (blue) from noise (gray) when true effects are rare. The Bayesian solutions …</p>
</section>
<section id="local-false-discovery-rate-lfdr" class="slide level2">
<h2>Local False Discovery Rate (LFDR)</h2>
<p>The key insight from Matthew Stephens’ work:</p>
<p>Instead of controlling the overall FDR, we can calculate the probability that each individual test is a false discovery:</p>
<p><span class="math display">\[\text{LFDR}(z) = P(H_0|z) = \frac{(1-\pi_1)f_0(z)}{f(z)}\]</span></p>
<p>Where:</p>
<p>- <span class="math inline">\(\pi_1\)</span> = proportion of true effects</p>
<p>- <span class="math inline">\(f_0(z)\)</span> = null distribution</p>
<p>- <span class="math inline">\(f(z)\)</span> = observed distribution</p>
</section>
<section id="plotting" class="slide level2">
<h2>plotting</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href=""></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1-2"><a href=""></a>n_tests <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb1-3"><a href=""></a>pi1 <span class="ot">&lt;-</span> <span class="fl">0.10</span>  <span class="co"># 10% true effects</span></span>
<span id="cb1-4"><a href=""></a>sigma <span class="ot">&lt;-</span> <span class="dv">4</span>    <span class="co"># Effect size parameter</span></span>
<span id="cb1-5"><a href=""></a></span>
<span id="cb1-6"><a href=""></a><span class="co"># Generate true and null effects</span></span>
<span id="cb1-7"><a href=""></a>n_true <span class="ot">&lt;-</span> <span class="fu">round</span>(n_tests <span class="sc">*</span> pi1)</span>
<span id="cb1-8"><a href=""></a>n_null <span class="ot">&lt;-</span> n_tests <span class="sc">-</span> n_true</span>
<span id="cb1-9"><a href=""></a></span>
<span id="cb1-10"><a href=""></a><span class="co"># Null effects</span></span>
<span id="cb1-11"><a href=""></a>z_null <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_null, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb1-12"><a href=""></a><span class="co"># True effects</span></span>
<span id="cb1-13"><a href=""></a>z_true <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_true, <span class="dv">0</span>, <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">+</span> sigma<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb1-14"><a href=""></a></span>
<span id="cb1-15"><a href=""></a><span class="co"># Calculate LFDR for each z-score</span></span>
<span id="cb1-16"><a href=""></a>calc_lfdr <span class="ot">&lt;-</span> <span class="cf">function</span>(z, <span class="at">pi1=</span><span class="fl">0.10</span>, <span class="at">sigma=</span><span class="dv">4</span>) {  <span class="co"># Match the parameters used to generate data</span></span>
<span id="cb1-17"><a href=""></a>  f0 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(z, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb1-18"><a href=""></a>  f1 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(z, <span class="dv">0</span>, <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">+</span> sigma<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb1-19"><a href=""></a>  f <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">-</span>pi1)<span class="sc">*</span>f0 <span class="sc">+</span> pi1<span class="sc">*</span>f1</span>
<span id="cb1-20"><a href=""></a>  (<span class="dv">1</span><span class="sc">-</span>pi1)<span class="sc">*</span>f0<span class="sc">/</span>f</span>
<span id="cb1-21"><a href=""></a>}</span>
<span id="cb1-22"><a href=""></a></span>
<span id="cb1-23"><a href=""></a><span class="co"># Create data frame</span></span>
<span id="cb1-24"><a href=""></a>plot_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-25"><a href=""></a>  <span class="at">z_score =</span> <span class="fu">c</span>(z_null, z_true),</span>
<span id="cb1-26"><a href=""></a>  <span class="at">is_true =</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>, n_null), <span class="fu">rep</span>(<span class="dv">1</span>, n_true))),</span>
<span id="cb1-27"><a href=""></a>  <span class="at">lfdr =</span> <span class="fu">c</span>(</span>
<span id="cb1-28"><a href=""></a>    <span class="fu">calc_lfdr</span>(z_null),</span>
<span id="cb1-29"><a href=""></a>    <span class="fu">calc_lfdr</span>(z_true)</span>
<span id="cb1-30"><a href=""></a>  )</span>
<span id="cb1-31"><a href=""></a>)</span>
<span id="cb1-32"><a href=""></a></span>
<span id="cb1-33"><a href=""></a><span class="co"># Plot with some improvements</span></span>
<span id="cb1-34"><a href=""></a><span class="fu">ggplot</span>(plot_data, <span class="fu">aes</span>(<span class="at">x =</span> z_score, <span class="at">y =</span> lfdr, <span class="at">color =</span> is_true)) <span class="sc">+</span></span>
<span id="cb1-35"><a href=""></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span>  <span class="co"># Smaller points, more transparency</span></span>
<span id="cb1-36"><a href=""></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.1</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"darkgreen"</span>) <span class="sc">+</span></span>
<span id="cb1-37"><a href=""></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"0"</span> <span class="ot">=</span> <span class="st">"gray70"</span>, <span class="st">"1"</span> <span class="ot">=</span> <span class="st">"blue"</span>),</span>
<span id="cb1-38"><a href=""></a>                    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Null"</span>, <span class="st">"True Effect"</span>),</span>
<span id="cb1-39"><a href=""></a>                    <span class="at">name =</span> <span class="st">"Truth"</span>) <span class="sc">+</span></span>
<span id="cb1-40"><a href=""></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Local False Discovery Rate"</span>,</span>
<span id="cb1-41"><a href=""></a>       <span class="at">subtitle =</span> <span class="fu">paste0</span>(<span class="st">"π₁ = "</span>, pi1, <span class="st">", σ = "</span>, sigma),</span>
<span id="cb1-42"><a href=""></a>       <span class="at">x =</span> <span class="st">"Z-score"</span>, </span>
<span id="cb1-43"><a href=""></a>       <span class="at">y =</span> <span class="st">"LFDR"</span>) <span class="sc">+</span></span>
<span id="cb1-44"><a href=""></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">16</span>) <span class="sc">+</span></span>
<span id="cb1-45"><a href=""></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="dv">6</span>))  <span class="co"># F</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-6-1.png" width="960" class="r-stretch"></section>
<section id="why-lfdr-is-better" class="slide level2">
<h2>Why LFDR is Better</h2>
<ol type="1">
<li><strong>Test-specific</strong>: Each test gets its own probability of being false</li>
<li><strong>Direct interpretation</strong>: “This test has 5% chance of being false”</li>
<li><strong>Natural handling of correlation</strong>: No need for independence assumptions</li>
<li><strong>Flexible</strong>: Can incorporate prior information about effect sizes</li>
</ol>
</section>
<section id="empirical-bayes-approach" class="slide level2">
<h2>Empirical Bayes Approach</h2>
<p>Matthew Stephens’ key contributions:</p>
<ol type="1">
<li><strong>Estimate from data</strong>: Learn <span class="math inline">\(\pi_1\)</span> and effect size distribution from the data</li>
<li><strong>Adaptive shrinkage</strong>: Stronger shrinkage for uncertain estimates</li>
<li><strong>Correlation structure</strong>: Account for LD and other dependencies</li>
</ol>
</section>
<section id="empirical-bayes-approach-1" class="slide level2">
<h2>Empirical Bayes Approach</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-7-1.png" width="960" class="r-stretch"></section>
<section id="practical-implementation" class="slide level2">
<h2>Practical Implementation</h2>
<ol type="1">
<li><strong>ashr</strong>: Adaptive shrinkage for effect sizes</li>
<li><strong>mashr</strong>: Multivariate adaptive shrinkage</li>
<li><strong>flashier</strong>: Sparse factor analysis (more on aladynoulli to come … )</li>
</ol>
</section>
<section id="the-mathematical-framework" class="slide level2">
<h2>The Mathematical Framework</h2>
<p>In multiple testing, we have two distributions:</p>
<ol type="1">
<li><p><strong>Null Distribution</strong> (<span class="math inline">\(f_0\)</span>): <span class="math display">\[f_0(z) = \mathcal{N}(0, se^2)\]</span> This is the standard normal distribution for tests where <span class="math inline">\(H_0\)</span> is true.</p></li>
<li><p><strong>Alternative Distribution</strong> (<span class="math inline">\(f_1\)</span>): <span class="math display">\[f_1(z) = \mathcal{N}(0, se^2 + \sigma^2)\]</span> This is a normal distribution with increased variance for tests where <span class="math inline">\(H_1\)</span> is true.</p></li>
<li><p><strong>Overall Distribution</strong> (<span class="math inline">\(f\)</span>): <span class="math display">\[f(z) = (1-\pi_1)f_0(z) + \pi_1f_1(z)\]</span> A mixture of null and alternative distributions (estimate posterior probability of non-null components) Homework!</p></li>
</ol>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-8-1.png" width="1440" class="r-stretch"></section>
<section id="effect-of-prior-variance-on-shrinkage" class="slide level2">
<h2>Effect of Prior Variance on Shrinkage</h2>
<p>The prior variance (<span class="math inline">\(\sigma^2\)</span>) directly affects how much we shrink our estimates:</p>
<ol type="1">
<li><strong>Small prior variance</strong> (<span class="math inline">\(\sigma^2\)</span> small):
<ul>
<li>Alternative distribution is narrow</li>
<li>Strong shrinkage toward zero</li>
<li>Conservative estimates</li>
<li>Higher threshold for calling something significant</li>
</ul></li>
<li><strong>Large prior variance</strong> (<span class="math inline">\(\sigma^2\)</span> large):
<ul>
<li><p>Alternative distribution is wide</p></li>
<li><p>Less shrinkage toward zero</p></li>
<li><p>More willing to accept large effect sizes</p></li>
<li><p>Lower threshold for calling something significant</p></li>
</ul></li>
</ol>
</section>
<section class="slide level2">


<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-9-1.png" width="1440" class="r-stretch"></section>
<section class="slide level2">

<p>This relationship between prior variance and shrinkage is crucial in genomics:</p>
<ul>
<li>For rare variants or small studies: Use smaller <span class="math inline">\(\sigma^2\)</span> to be conservative</li>
<li>For common variants or large studies: Can use larger <span class="math inline">\(\sigma^2\)</span></li>
<li>For follow-up studies: Can use previous effect size estimates to inform <span class="math inline">\(\sigma^2\)</span></li>
</ul>
</section>
<section id="multivariate-adaptive-shrinkage-mash" class="slide level2">
<h2>Multivariate Adaptive Shrinkage (mash)</h2>
<p>When we have effects across multiple groups (e.g., tissues, conditions), we can borrow strength:</p>
<p><span class="math display">\[\begin{align*}
\text{Effects across groups: } &amp; \mathbf{B}_j \sim N(\mathbf{0}, \mathbf{U}_k) \\
\text{Mixture model: } &amp; p(\mathbf{B}_j) = \sum_{k=1}^K \pi_k N(\mathbf{0}, \mathbf{U}_k)
\end{align*}\]</span></p>
<p>Where <span class="math inline">\(\mathbf{U}_k\)</span> captures different patterns of sharing: - Equal effects across groups - Group-specific effects - Correlated effects - Structured patterns</p>
</section>
<section id="understanding-covariance-matrices-in-multivariate-normal-distribution" class="slide level2">
<h2>Understanding Covariance Matrices in Multivariate Normal Distribution</h2>
<p>Let’s consider a bivariate normal distribution with covariance matrix U_k:</p>
<p><span class="math display">\[\mathbf{U}\_k =
\begin{pmatrix}
\sigma^2_1 &amp; \rho\sigma_1\sigma_2 \\
\rho\sigma_1\sigma_2 &amp; \sigma^2_2
\end{pmatrix}\]</span></p>
<p>where: - <span class="math inline">\(\sigma\^2_1\)</span> and <span class="math inline">\(\sigma\^2_2\)</span> are the variances for each trait - <span class="math inline">\(\rho\)</span> is the correlation coefficient - <span class="math inline">\(\rho\sigma\_1\sigma\_2\)</span> represents the covariance.</p>
</section>
<section id="more-math" class="slide level2">
<h2>More math</h2>
<p>The multivariate normal density is then:</p>
<p><span class="math display">\[\mathbf{x}\|\mathbf{U}\_k) = \frac{1}{2\pi|\mathbf{U}_k|^{1/2}}
\exp\left(-\frac{1}{2}\mathbf{x}\^T\mathbf{U}\_k\^{-1}\mathbf{x}\right)\]</span></p>
<p>Different covariance matrices (_k) lead to different shapes:</p>
<ol type="1">
<li>When (<span class="math inline">\(\rho\)</span> = 0):
<ul>
<li>Effects are independent</li>
<li>Contours form circles/ellipses aligned with axes</li>
</ul></li>
<li>When (<span class="math inline">\(\rho\)</span> <span class="math inline">\(\neq\)</span> 0):
<ul>
<li>Effects are correlated</li>
<li>Contours form rotated ellipses</li>
<li>Direction of rotation determined by sign of ()</li>
</ul></li>
</ol>
</section>
<section id="how-would-you-get-a-11-line" class="slide level2">
<h2>How would you get a 1:1 line?</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href=""></a><span class="fu">library</span>(MASS)</span>
<span id="cb2-2"><a href=""></a>sig1 <span class="ot">=</span><span class="dv">2</span>;sig2<span class="ot">=</span><span class="dv">3</span></span>
<span id="cb2-3"><a href=""></a>cov1<span class="ot">=</span><span class="fu">matrix</span>(<span class="fu">c</span>(sig1<span class="sc">^</span><span class="dv">2</span>,sig1<span class="sc">*</span>sig2,sig2<span class="sc">*</span>sig1,sig2<span class="sc">^</span><span class="dv">2</span>),<span class="at">byrow =</span> <span class="cn">TRUE</span>,<span class="at">nrow=</span><span class="dv">2</span>)</span>
<span id="cb2-4"><a href=""></a>m<span class="ot">=</span><span class="fu">mvrnorm</span>(<span class="dv">10000</span>,<span class="at">mu =</span> <span class="fu">rep</span>(<span class="dv">0</span>,<span class="dv">2</span>),<span class="at">Sigma =</span> cov1)</span>
<span id="cb2-5"><a href=""></a><span class="fu">plot</span>(m[,<span class="dv">1</span>],m[,<span class="dv">2</span>],<span class="at">xlab=</span><span class="st">"Effect 1"</span>,<span class="at">ylab=</span><span class="st">"Effect 2"</span>)</span>
<span id="cb2-6"><a href=""></a><span class="fu">abline</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-10-1.png" width="960" class="r-stretch"></section>
<section id="bringing-it-home" class="slide level2">
<h2>Bringing it home!</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-11-1.png" width="960" class="r-stretch"><ul>
<li>Observed Effects are noisy</li>
<li>only considering information in one subgroup ignores the hints we get from abound</li>
<li>sharing is caring!</li>
</ul>
</section>
<section id="conjugate-priors-why-theyre-beautiful" class="slide level2">
<h2>Conjugate Priors: Why They’re Beautiful</h2>
<p><strong>Definition</strong>: A prior is conjugate when the posterior has the same distribution family as the prior.</p>
<p>Let’s see this mathematically:</p>
</section>
<section id="conjugate-priors-why-theyre-beautiful-1" class="slide level2">
<h2>Conjugate Priors: Why They’re Beautiful</h2>
<p>For example, in the Normal-Normal case: [ <span class="math display">\[\begin{align}
\text{Prior: } &amp; \theta \sim N(\mu_0, \sigma^2_0) \\
\text{Likelihood: } &amp; X|\theta \sim N(\theta, \sigma^2) \\
\text{Posterior: } &amp; \theta|X \sim N\left(\frac{\sigma^2_0 X + \sigma^2\mu_0}{\sigma^2_0 + \sigma^2}, \frac{\sigma^2_0\sigma^2}{\sigma^2_0 + \sigma^2}\right)
\end{align}\]</span></p>
<p>The beauty is that: 1. Prior starts as Normal 2. Data comes from Normal 3. Posterior ends up Normal 4. Just with updated parameters!</p>
<p>This makes computation tractable and interpretation intuitive - we’re just updating our beliefs while staying in the same family of distributions.</p>
</section>
<section id="beta-binomial-perfect-for-allele-frequencies" class="slide level2">
<h2>Beta-Binomial: Perfect for Allele Frequencies</h2>
<p><strong>Model</strong>:<br>
- <strong>Prior</strong>: <span class="math inline">\(\theta \sim \text{Beta}(\alpha, \beta)\)</span><br>
- <strong>Likelihood</strong>: <span class="math inline">\(X|\theta \sim \text{Binomial}(n, \theta)\)</span><br>
- <strong>Posterior</strong>: <span class="math inline">\(\theta|X \sim \text{Beta}(\alpha + X, \beta + n - X)\)</span></p>
</section>
<section id="beta-binomial-perfect-for-allele-frequencies-1" class="slide level2">
<h2>Beta-Binomial: Perfect for Allele Frequencies</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-12-1.png" width="960" class="r-stretch"></section>
<section id="beta-binomial-conjugacy-adding-counts-intuition" class="slide level2">
<h2>Beta-Binomial Conjugacy: Adding Counts Intuition</h2>
<p>The <span class="math inline">\(\beta(\alpha, \beta)\)</span> distribution updates by simply adding successes to (<span class="math inline">\(\alpha\)</span>) and failures to (<span class="math inline">\(\beta\)</span>)!</p>
<p><span class="math display">\[\begin{align}
\text{Prior: } &amp; \theta \sim \text{Beta}(\alpha_0, \beta_0) \\
\text{Data: } &amp; \text{Observe: } s \text{ successes, } f \text{ failures} \\
\text{Posterior: } &amp; \theta \sim \text{Beta}(\alpha_0 + s, \beta_0 + f)
\end{align}\]</span></p>
</section>
<section id="simple-example" class="slide level2">
<h2>Simple Example:</h2>
<p>Imagine tracking minor allele frequency:</p>
<ul>
<li><p><strong>Start</strong>: Beta(2, 8) - prior belief allele is rare</p></li>
<li><p><strong>Observe</strong>: AABB AABB ABBB (5 A’s, 7 B’s)</p></li>
<li><p><strong>Updates</strong>: - After 1st group: Beta(4, 10)</p></li>
<li><p>After 2nd group: Beta(6, 12)</p></li>
<li><p>After 3rd group: Beta(7, 15)</p></li>
</ul>
</section>
<section id="why-this-is-beautiful" class="slide level2">
<h2>Why this is beautiful:</h2>
<ol type="1">
<li>Each A (success) adds 1 to ($$)</li>
<li>Each B (failure) adds 1 to ($$)</li>
<li>(<span class="math inline">\(\alpha\)</span>) = prior successes + observed successes</li>
<li>(<span class="math inline">\(\beta\)</span>) = prior failures + observed failures</li>
<li>Posterior mean = (<span class="math inline">\(\frac{\alpha}{\alpha + \beta}\)</span>)</li>
</ol>
</section>
<section id="continuous-updating" class="slide level2">
<h2>Continuous updating</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-13-1.png" width="960" class="r-stretch"></section>
<section id="dirichlet-multinomial-for-multiple-alleles" class="slide level2">
<h2>Dirichlet-Multinomial: For Multiple Alleles</h2>
<p><strong>Model</strong>:<br>
- <strong>Prior</strong>: <span class="math inline">\(\vec{\theta} \sim \text{Dirichlet}(\vec{\alpha})\)</span><br>
- <strong>Likelihood</strong>: <span class="math inline">\(\vec{X}|\vec{\theta} \sim \text{Multinomial}(n, \vec{\theta})\)</span><br>
- <strong>Posterior</strong>: <span class="math inline">\(\vec{\theta}|\vec{X} \sim \text{Dirichlet}(\vec{\alpha} + \vec{X})\)</span></p>
<h3 id="key-intuition">Key Intuition:</h3>
<p>The Dirichlet-Multinomial is just like Beta-Binomial, but for multiple categories instead of just two!</p>
<p><span class="math inline">\(\begin{align}
\text{Prior: } &amp; \vec{\theta} \sim \text{Dirichlet}(\alpha_1, \alpha_2, ..., \alpha_K) \\
\text{Data: } &amp; \vec{X} = (x_1, x_2, ..., x_K) \text{ counts in each category} \\
\text{Posterior: } &amp; \vec{\theta} \sim \text{Dirichlet}(\alpha_1 + x_1, \alpha_2 + x_2, ..., \alpha_K + x_K)
\end{align}\)</span></p>
</section>
<section id="simple-example-1" class="slide level2">
<h2>Simple Example:</h2>
<p>Imagine tracking allele frequencies for three alleles (A, B, C):</p>
<ul>
<li><p><strong>Prior</strong>: Dirichlet(2, 2, 2)</p></li>
<li><p>equally uncertain about all alleles</p></li>
<li><p><strong>Observe</strong>: 10 A’s, 5 B’s, 3 C’s</p></li>
<li><p><strong>Posterior</strong>: Dirichlet(12, 7, 5) - just add counts to prior parameters!</p></li>
</ul>
<h3 id="why-this-is-beautiful-1">Why this is beautiful:</h3>
<ol type="1">
<li>Each observation simply adds 1 to its category’s parameter</li>
<li>($_k$) can be thought of as “pseudo-counts”</li>
<li>Larger prior ($$)’s = stronger prior beliefs</li>
<li>Sum of ($$)’s = sample size of prior belief</li>
<li>Posterior mean for category k: ($$)</li>
</ol>
</section>
<section id="why-this-is-beautiful-2" class="slide level2">
<h2>Why this is beautiful:</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-14-1.png" width="960" class="r-stretch"></section>
<section id="conjugate-normal-normal-model" class="slide level2">
<h2>Conjugate Normal-Normal Model</h2>
<ul>
<li>One of the most elegant and widely-used conjugate pairs in Bayesian statistics<br>
</li>
<li>Perfect for analyzing quantitative traits in genomics<br>
</li>
<li>Gives us a mathematical shortcut for updating beliefs</li>
</ul>
</section>
<section id="the-setup" class="slide level2">
<h2>The Setup</h2>
<p>When analyzing a continuous parameter <span class="math inline">\(\mu\)</span> (like an effect size):</p>
<ul>
<li><p><strong>Prior</strong>: <span class="math inline">\(\mu \sim \mathcal{N}(\mu_0, \sigma_0^2)\)</span><br>
</p></li>
<li><p><strong>Likelihood</strong>: <span class="math inline">\(X \sim \mathcal{N}(\mu, \sigma^2)\)</span> where <span class="math inline">\(\sigma^2\)</span> is known<br>
</p></li>
<li><h2 id="question-what-is-pmux"><strong>Question</strong>: What is <span class="math inline">\(p(\mu|X)\)</span>?</h2></li>
</ul>
</section>
<section id="the-mathematical-magic" class="slide level2">
<h2>The Mathematical Magic</h2>
<p>The elegance is in the algebraic symmetry:</p>
<p><span class="math display">\[
\begin{align}
p(\mu|X) &amp;\propto p(X|\mu) \times p(\mu)\\
&amp;\propto \exp\left(-\frac{(X-\mu)^2}{2\sigma^2}\right) \times \exp\left(-\frac{(\mu-\mu_0)^2}{2\sigma_0^2}\right)
\end{align}
\]</span></p>
<p>Notice the beautiful symmetry: <span class="math inline">\((X-\mu)^2\)</span> in the likelihood and <span class="math inline">\((\mu-\mu_0)^2\)</span> in the prior.</p>
</section>
<section id="the-key-insight" class="slide level2">
<h2>The Key Insight</h2>
<p>When we expand these terms:</p>
<p><span class="math display">\[
\begin{align}
p(\mu|X) &amp;\propto \exp\left(-\frac{1}{2}\left[\frac{(X-\mu)^2}{\sigma^2} + \frac{(\mu-\mu_0)^2}{\sigma_0^2}\right]\right)\\
&amp;\propto \exp\left(-\frac{1}{2}\left[\frac{\mu^2 - 2\mu X + X^2}{\sigma^2} + \frac{\mu^2 - 2\mu\mu_0 + \mu_0^2}{\sigma_0^2}\right]\right)
\end{align}
\]</span></p>
<p>Collecting terms with <span class="math inline">\(\mu^2\)</span> and <span class="math inline">\(\mu\)</span>…</p>
</section>
<section id="the-posterior-formula" class="slide level2">
<h2>The Posterior Formula</h2>
<p>After completing the square, we get:</p>
<p><span class="math display">\[\mu|X \sim \mathcal{N}(\mu_n, \sigma_n^2)\]</span></p>
<p>Where:</p>
<p><span class="math display">\[\mu_n = \frac{\frac{\mu_0}{\sigma_0^2} + \frac{X}{\sigma^2}}{\frac{1}{\sigma_0^2} + \frac{1}{\sigma^2}} = \frac{\sigma^2\mu_0 + \sigma_0^2 X}{\sigma^2 + \sigma_0^2}\]</span></p>
<p><span class="math display">\[\frac{1}{\sigma_n^2} = \frac{1}{\sigma_0^2} + \frac{1}{\sigma^2}\]</span></p>
</section>
<section id="a-more-intuitive-view" class="slide level2">
<h2>A More Intuitive View</h2>
<p>The posterior mean is a <strong>precision-weighted average</strong> of the prior mean and the data:</p>
<p><span class="math display">\[\mu_n = w\mu_0 + (1-w)X\]</span></p>
<p>Where <span class="math inline">\(w = \frac{\sigma^2}{\sigma^2 + \sigma_0^2} = \frac{\text{data precision}}{\text{total precision}}\)</span></p>
<ul>
<li>When data is precise (small <span class="math inline">\(\sigma^2\)</span>): we trust the data more<br>
</li>
<li>When prior is precise (small <span class="math inline">\(\sigma_0^2\)</span>): we trust the prior more</li>
</ul>
</section>
<section id="multiple-observations" class="slide level2">
<h2>Multiple Observations</h2>
<p>With multiple observations <span class="math inline">\(X_1,...,X_n\)</span>, we get:</p>
<p><span class="math display">\[\mu|(X_1,...,X_n) \sim \mathcal{N}\left(\frac{\frac{\mu_0}{\sigma_0^2} + \frac{n\bar{X}}{\sigma^2}}{\frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}}, \left(\frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}\right)^{-1}\right)\]</span></p>
<ul>
<li>The sample mean <span class="math inline">\(\bar{X}\)</span> is a sufficient statistic<br>
</li>
<li>More data increases precision linearly</li>
</ul>
</section>
<section id="genomics-application-eqtl-effect-sizes" class="slide level2">
<h2>Genomics Application: eQTL Effect Sizes</h2>
<p>In genomics, we might use this model for:</p>
<ul>
<li><strong>Prior</strong>: Historical effect sizes for similar variants<br>
</li>
<li><strong>Likelihood</strong>: Observed effect in current study<br>
</li>
<li><strong>Posterior</strong>: Updated estimate that balances prior knowledge and new data</li>
</ul>
<p>Example: Effect sizes for expression quantitative trait loci (eQTLs)</p>
</section>
<section id="the-power-of-conjugate-priors" class="slide level2">
<h2>The Power of Conjugate Priors</h2>
<p>Advantages of conjugate Normal-Normal:</p>
<ol type="1">
<li><strong>Analytical solutions</strong> – no MCMC required<br>
</li>
<li><strong>Computational efficiency</strong> – critical for genomic scale<br>
</li>
<li><strong>Interpretable updates</strong> – precision-weighted averages<br>
</li>
<li><strong>Sequential processing</strong> – can update one observation at a time</li>
</ol>
</section>
<section id="normal-normal-key-takeaways" class="slide level2">
<h2>Normal-Normal: Key Takeaways</h2>
<ol type="1">
<li>The posterior is also Normal – that’s conjugacy!<br>
</li>
<li>The posterior mean is a weighted average of prior mean and data<br>
</li>
<li>Weights are determined by relative precisions (1/variance)<br>
</li>
<li>The posterior precision is the sum of the prior and data precisions<br>
</li>
<li>This model provides the foundation for many advanced Bayesian genomic methods</li>
</ol>
</section>
<section id="extension-empirical-bayes-for-normal-means" class="slide level2">
<h2>Extension: Empirical Bayes for Normal Means</h2>
<ul>
<li>When we don’t have a specific prior, we can <strong>estimate it from the data</strong><br>
</li>
<li>This approach, known as <strong>Empirical Bayes</strong>, is extremely powerful for genomics<br>
</li>
<li>Applications include: multiple testing, sparse signal detection, and effect size estimation</li>
</ul>
</section>
<section id="methods-using-normal-normal-conjugacy" class="slide level2">
<h2>Methods Using Normal-Normal Conjugacy</h2>
<ul>
<li><strong>Adaptive Shrinkage (ash)</strong>: Uses a mixture of normals as the prior<br>
</li>
<li><strong>Multivariate Adaptive Shrinkage (mash)</strong>: Extends to correlated effects across conditions<br>
</li>
<li><strong>False Discovery Rate Control</strong>: Through local false discovery rates<br>
</li>
<li><strong>Hierarchical Models</strong>: Building multi-level models with partially pooled estimates</li>
</ul>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="mixture-models-for-complex-data-what-are-mixture-models" class="title-slide slide level1 center">
<h1>Mixture Models for Complex Data: What Are Mixture Models?</h1>
<p>Mixture models are probabilistic models that represent the presence of subpopulations within an overall population:</p>
<ul>
<li><strong>Used when data come from multiple underlying processes</strong><br>
</li>
<li><strong>Represent heterogeneous populations as mixtures of simpler distributions</strong><br>
</li>
<li><strong>Allow clustering without hard assignments</strong><br>
</li>
<li><strong>Incorporate uncertainty in group membership</strong></li>
</ul>
</section>
<section id="mixture-model-mathematical-formulation" class="slide level2">
<h2>Mixture Model: Mathematical Formulation</h2>
<p>A mixture model combines multiple distributions to model complex data:</p>
<p><span class="math display">\[p(x) = \sum_{k=1}^K \pi_k f_k(x|\theta_k)\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(p(x)\)</span> is the overall probability density<br>
</li>
<li><span class="math inline">\(K\)</span> is the number of components (subpopulations)<br>
</li>
<li><span class="math inline">\(\pi_k\)</span> are the mixing weights (<span class="math inline">\(\sum_{k=1}^K \pi_k = 1\)</span>)<br>
</li>
<li><span class="math inline">\(f_k(x|\theta_k)\)</span> are the component densities with parameters <span class="math inline">\(\theta_k\)</span></li>
</ul>
</section>
<section id="a-closer-look-at-the-components" class="slide level2">
<h2>A Closer Look at the Components</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Key components</strong>:</p>
<ol type="1">
<li><strong>Component distributions</strong> <span class="math inline">\(f_k(x|\theta_k)\)</span>
<ul>
<li>Each represents a subpopulation<br>
</li>
<li>Can be any distribution family<br>
</li>
<li>Common choices: Gaussian, multinomial, beta</li>
</ul></li>
<li><strong>Mixing weights</strong> <span class="math inline">\(\pi_k\)</span>
<ul>
<li>Proportion of data from each component<br>
</li>
<li>Must sum to 1: <span class="math inline">\(\sum_{k=1}^K \pi_k = 1\)</span><br>
</li>
<li>Reflect prior probabilities of group membership</li>
</ul></li>
<li><strong>Latent variables</strong> <span class="math inline">\(z_i\)</span>
<ul>
<li>Unobserved component membership<br>
</li>
<li><span class="math inline">\(z_i = k\)</span> means data point <span class="math inline">\(i\)</span> came from component <span class="math inline">\(k\)</span></li>
</ul></li>
</ol>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="mpg6_files/figure-revealjs/unnamed-chunk-15-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="likelihood-function-for-mixture-models" class="slide level2">
<h2>Likelihood Function for Mixture Models</h2>
<p>The likelihood of a mixture model for <span class="math inline">\(n\)</span> independent observations <span class="math inline">\(x_1, \ldots, x_n\)</span> is:</p>
<p><span class="math display">\[L(\theta, \pi | x_1, \ldots, x_n) = \prod_{i=1}^n p(x_i) = \prod_{i=1}^n \sum_{k=1}^K \pi_k f_k(x_i|\theta_k)\]</span></p>
<p><strong>Challenge</strong>: The sum inside the product makes this difficult to optimize directly</p>
<p><strong>Solution</strong>: Introduce latent variables <span class="math inline">\(z_i\)</span> and use the EM algorithm</p>
</section>
<section id="the-em-algorithm-in-detail" class="slide level2">
<h2>The EM Algorithm in Detail</h2>
<p>The Expectation-Maximization (EM) algorithm is an iterative method for finding maximum likelihood estimates:</p>
<p><strong>E-step</strong>: Calculate “responsibilities” – the posterior probability that data point <span class="math inline">\(i\)</span> belongs to component <span class="math inline">\(k\)</span>:</p>
<p><span class="math display">\[\gamma_{ik} = P(z_i = k | x_i, \theta) = \frac{\pi_k f_k(x_i|\theta_k)}{\sum_{j=1}^K \pi_j f_j(x_i|\theta_j)}\]</span></p>
<p><strong>M-step</strong>: Update parameters using weighted maximum likelihood:</p>
<p><span class="math display">\[\pi_k^{new} = \frac{1}{n}\sum_{i=1}^n \gamma_{ik}\]</span><br>
<span class="math display">\[\theta_k^{new} = \arg\max_{\theta_k} \sum_{i=1}^n \gamma_{ik} \log f_k(x_i|\theta_k)\]</span></p>
</section>
<section id="em-algorithm-step-by-step-example" class="slide level2">
<h2>EM Algorithm: Step-by-Step Example</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-16-1.png" width="960" class="r-stretch"></section>
<section id="worked-example-em-algorithm-step-by-step" class="slide level2">
<h2>Worked Example: EM Algorithm Step-by-Step</h2>
<p>Let’s walk through each step of the EM algorithm for a mixture of two Gaussians:</p>
<ol type="1">
<li><strong>Initialize parameters</strong>:
<ul>
<li>Set initial mixing weights: <span class="math inline">\(\pi_1 = \pi_2 = 0.5\)</span><br>
</li>
<li>Set initial component means: <span class="math inline">\(\mu_1 = -1, \mu_2 = 1\)</span><br>
</li>
<li>Set initial component standard deviations: <span class="math inline">\(\sigma_1 = \sigma_2 = 1\)</span></li>
</ul></li>
<li><strong>E-step</strong>: For each data point <span class="math inline">\(x_i\)</span>, calculate the responsibility of each component:
<ul>
<li><span class="math inline">\(\gamma_{i1} = \frac{\pi_1 N(x_i|\mu_1,\sigma_1^2)}{\pi_1 N(x_i|\mu_1,\sigma_1^2) + \pi_2 N(x_i|\mu_2,\sigma_2^2)}\)</span><br>
</li>
<li><span class="math inline">\(\gamma_{i2} = 1 - \gamma_{i1}\)</span></li>
</ul></li>
<li><strong>M-step</strong>: Update the parameters using the responsibilities:
<ul>
<li><span class="math inline">\(\pi_1^{new} = \frac{1}{n}\sum_{i=1}^n \gamma_{i1}\)</span> (similarly for <span class="math inline">\(\pi_2^{new}\)</span>)<br>
</li>
<li><span class="math inline">\(\mu_1^{new} = \frac{\sum_{i=1}^n \gamma_{i1}x_i}{\sum_{i=1}^n \gamma_{i1}}\)</span> (similarly for <span class="math inline">\(\mu_2^{new}\)</span>)<br>
</li>
<li><span class="math inline">\((\sigma_1^{new})^2 = \frac{\sum_{i=1}^n \gamma_{i1}(x_i-\mu_1^{new})^2}{\sum_{i=1}^n \gamma_{i1}}\)</span> (similarly for <span class="math inline">\(\sigma_2^{new}\)</span>)</li>
</ul></li>
<li><strong>Repeat</strong> until convergence (parameters stop changing significantly)</li>
</ol>
</section>
<section class="slide level2">

<p>The EM Algorithm: Mathematical Intuition</p>
<p>Key insight: We’re solving a chicken-and-egg problem<br>
If we knew component assignments, parameter estimation would be easy<br>
If we knew parameters, component assignments would be easy<br>
EM iteratively solves both by using expected assignments</p>
<p>E-step (Expectation): Calculate expected component memberships<br>
<span class="math display">\[\gamma_{ik} = P(z_i = k | x_i, \theta^{(t)}) = \frac{\pi_k^{(t)} f_k(x_i|\theta_k^{(t)})}{\sum_{j=1}^K \pi_j^{(t)} f_j(x_i|\theta_j^{(t)})}\]</span><br>
Intuition: “How likely is individual i to belong to population k, given our current parameter estimates?”</p>
<p>M-step (Maximization): Update parameters using weighted averages<br>
For mixing weights:<br>
<span class="math display">\[\pi_k^{(t+1)} = \frac{1}{n}\sum_{i=1}^n \gamma_{ik}\]</span><br>
Intuition: “The new population frequency is the average membership across all individuals”</p>
<p>For component means (Gaussian case):<br>
<span class="math display">\[\mu_k^{(t+1)} = \frac{\sum_{i=1}^n \gamma_{ik}x_i}{\sum_{i=1}^n \gamma_{ik}}\]</span><br>
Intuition: “The new population mean is a weighted average where individuals are weighted by their probability of belonging to this population (link interlude <a href="https://surbut.shinyapps.io/shinyP/" class="uri">https://surbut.shinyapps.io/shinyP/</a> )</p>
</section>
<section id="bayesian-mixture-models" class="slide level2">
<h2>Bayesian Mixture Models</h2>
<p>Bayesian mixture models add priors to the parameters:</p>
<p><span class="math inline">\(p(\theta, \pi | x_1, \ldots, x_n) \propto p(x_1, \ldots, x_n | \theta, \pi) \times p(\theta, \pi)\)</span></p>
<p>Common prior choices:<br>
- <span class="math inline">\(\pi \sim \text{Dirichlet}(\alpha_1, \ldots, \alpha_K)\)</span> for mixing weights<br>
- Component-specific priors for <span class="math inline">\(\theta_k\)</span> (e.g., Normal-Inverse-Gamma for Gaussian components)</p>
<p><strong>Advantages</strong>:<br>
- Handle uncertainty in the number of components (K)<br>
- Avoid singularities and improve stability<br>
- Allow for informed priors from previous studies<br>
- Provide full posterior distribution rather than point estimates (in full MCMC implementation, but SLOW)</p>
</section>
<section id="mixture-model-applications-in-genomics" class="slide level2">
<h2>Mixture Model Applications in Genomics</h2>
<p><strong>1. Population Structure</strong><br>
- Components = ancestral populations<br>
- Individual genotypes = admixtures of populations<br>
- Example: STRUCTURE, ADMIXTURE software<br>
- Used for: demographic history, association studies, conservation</p>
<p><strong>2. Genetic effect estimation</strong><br>
- (e.g., adaptive shrinkage methods like ash/mash for multiple conditions)</p>
<p><strong>3. Gene Expression Clustering</strong><br>
- Components = cell types/states<br>
- Expression patterns = signatures of cell types<br>
- Example: Single-cell RNA-seq clustering<br>
- Used for: cell type identification, developmental trajectories</p>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-17-1.png" width="960" class="r-stretch"></section>
<section id="the-structure-model-in-detail" class="slide level2">
<h2>The STRUCTURE Model in Detail</h2>
<p><strong>STRUCTURE</strong>: A Bayesian mixture model for population genetics</p>
<p><strong>Key components</strong>:<br>
- Each individual = mixture of <span class="math inline">\(K\)</span> ancestral populations<br>
- Each population = distinct allele frequencies<br>
- Goal: Infer ancestry proportions &amp; population frequencies from observed allele counts</p>
<p><strong>Bayesian formulation</strong>:<br>
- <strong>Prior</strong>: <span class="math inline">\(q_{ik} \sim \text{Dirichlet}(\alpha)\)</span> (ancestry proportions, population level alpha)<br>
- <strong>Prior</strong>: <span class="math inline">\(f_{kj} \sim \text{Beta}(\lambda)\)</span> (allele frequencies, population level lambda, f) - <strong>Likelihood</strong>: <span class="math inline">\(P(X_{ij} | q_i, f_j)\)</span> (genotype probabilities, i.e., probability of allele count given individual ancestry and populations allele frequency)</p>
</section>
<section id="latent-dirichlety-allocation" class="slide level2">
<h2>Latent Dirichlety Allocation</h2>
<p>Topic Models (LDA):</p>
<p>- Document mixture proportions θ ~ Dirichlet(α)</p>
<p>- Topic-word distributions φ ~ Dirichlet(β)</p>
<p>- Words drawn from topics z ~ Multinomial(θ)</p>
<p>STRUCTURE:</p>
<p>- Individual ancestry proportions q ~ Dirichlet(α)</p>
<p>- Population allele frequencies p ~ Dirichlet(β)</p>
<p>- Alleles drawn from populations z ~ Multinomial(q)</p>
</section>
<section id="visualization-if-we-know-the-truth" class="slide level2">
<h2>Visualization: If we know the truth</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-18-1.png" width="576" class="r-stretch"></section>
<section id="structure-a-tale-of-unknown-ancestries" class="slide level2">
<h2>STRUCTURE: A Tale of Unknown Ancestries</h2>
<p>Our Data (Haploid Genotypes): Individual M1 M2 M3 * Ind1: A C A * Ind2: G T G * Ind3: A T A</p>
<p>We want to find: K=2 ancestral populations</p>
</section>
<section id="key-point-different-distributions-for-different-reasons" class="slide level2">
<h2>Key Point: Different Distributions for Different Reasons</h2>
<p><span class="math inline">\(q (ancestry) ~ Dirichlet\)</span> - Because proportions sum to 1 across K populations - K parameters (one for each population) - NOT related to number of allele types</p>
<p>$f (frequencies) ~ Beta $ - Because each marker has 2 possible alleles - Two parameters (success/failure for that allele) - One Beta distribution per marker per population</p>
</section>
<section id="understanding-the-q-update-individual-level" class="slide level2">
<h2>Understanding the q Update (Individual Level)</h2>
<p><strong>Individual 1</strong>: A C A</p>
<ul>
<li>Step 1: Calculate Likelihoods <strong>Population 1 Contributions</strong>:</li>
<li>Marker 1 (A): <span class="math inline">\(L_{11} = f_1^A\)</span></li>
<li>Marker 2 (C): <span class="math inline">\(L_{21} = f_1^C\)</span></li>
<li>Marker 3 (A): <span class="math inline">\(L_{31} = f_1^A\)</span></li>
</ul>
<p>Total for Pop1 = <span class="math inline">\(L_{11} + L_{21} + L_{31}\)</span></p>
</section>
<section id="example-data" class="slide level2">
<h2>Example Data</h2>
<p><strong>Individual 1</strong>: A C A</p>
<p><strong>Population 2 Contributions</strong>:</p>
<ul>
<li>Marker 1 (A): <span class="math inline">\(L_{12} = f_2^A\)</span></li>
<li>Marker 2 (C): <span class="math inline">\(L_{22} = f_2^C\)</span></li>
<li>Marker 3 (A): <span class="math inline">\(L_{32} = f_2^A\)</span></li>
</ul>
<p>Total for Pop2 = <span class="math inline">\(L_{12} + L_{22} + L_{32}\)</span></p>
</section>
<section id="step-2-dirichlet-update" class="slide level2">
<h2>Step 2: Dirichlet Update</h2>
<p><span class="math display">\[q_1 \sim \text{Dirichlet}(\alpha + [\text{Sum\_Pop1}, \text{Sum\_Pop2}])\]</span> where:</p>
<p><em>-</em> Sum_Pop1 = <span class="math inline">\(L_{11} + L_{21} + L_{31}\)</span> (added to <span class="math inline">\(\alpha_1\)</span>) <em>-</em> Sum_Pop2 = <span class="math inline">\(L_{12} + L_{22} + L_{32}\)</span> (added to <span class="math inline">\(\alpha_2\)</span>)</p>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>The Dirichlet update incorporates likelihood contributions from both populations to estimate how much of Individual 1’s ancestry comes from each population.</p>
</div>
</div>
</div>
</section>
<section id="updating-allele-frequencies-f-with-fixed-ancestry-q" class="slide level2">
<h2>Updating Allele Frequencies (f) with Fixed Ancestry (q)</h2>
<p>** Marker 1 (Allele A)</p>
<p><strong>Individual 1’s ancestry</strong>: <span class="math inline">\(q_1 = (0.7, 0.3)\)</span></p>
<p><strong>Population 1</strong>: - Contribution from Individual 1: 0.7 (from <span class="math inline">\(q_{11}\)</span>) - Update: <span class="math inline">\(f_1^A \sim \text{Beta}(\lambda + 0.7, \lambda + 0.3)\)</span></p>
<p><strong>Population 2</strong>: - Contribution from Individual 1: 0.3 (from <span class="math inline">\(q_{12}\)</span>) - Update: <span class="math inline">\(f_2^A \sim \text{Beta}(\lambda + 0.3, \lambda + 0.7)\)</span></p>
</section>
<section id="marker-2-allele-c" class="slide level2">
<h2>Marker 2 (Allele C)</h2>
<p><strong>Population 1</strong> - Contribution from Individual 1: 0.7 (from <span class="math inline">\(q_{11}\)</span>) - Update: <span class="math inline">\(f_1^C \sim \text{Beta}(\lambda + 0.7, \lambda + 0.3)\)</span></p>
<p><strong>Population 2</strong>: - Contribution from Individual 1: 0.3 (from <span class="math inline">\(q_{12}\)</span>) - Update: <span class="math inline">\(f_2^C \sim \text{Beta}(\lambda + 0.3, \lambda + 0.7)\)</span></p>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>Note that each allele contributes fractionally to each population’s frequency estimate, weighted by the individual’s ancestry proportions.</p>
</div>
</div>
</div>
</section>
<section id="the-mcmc-two-step" class="slide level2">
<h2>The MCMC Two-Step</h2>
<ol type="1">
<li><p>Update ancestries given current frequencies: <span class="math inline">\(P(q_i \|\text{data}, f) \propto P(\text{data}\|q_i,f)P(q_i)\)</span></p></li>
<li><p>Update frequencies given current ancestries: <span class="math inline">\(P(f_k | \text{data}, q) \propto P(\text{data}|q,f_k)P(f_k)\)</span></p></li>
</ol>
<h3 id="effect-size-mixtures-in-gwas"><strong>Effect Size Mixtures in GWAS</strong></h3>
<p><strong>Problem</strong>: Most variants have no effect, but some do</p>
<p><strong>Solutions</strong>:<br>
- <strong>Spike-and-slab prior</strong>: Mixture of point mass at zero and continuous distribution<br>
- <strong>Scale mixture</strong>: Mixture of normal distributions with different variances<br>
- <strong>Bayesian variable selection</strong>: Latent indicator for whether variant is causal</p>
<p><strong>Benefits</strong>:<br>
- Controls false discovery rate<br>
- Improves power to detect true associations<br>
- Provides interpretable posterior probabilities<br>
- Naturally handles multiple testing</p>
</section>
<section id="sound-familiar-multiple-hypothesis-testing" class="slide level2">
<h2>Sound familiar? Multiple hypothesis testing!</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href=""></a><span class="co"># Create visualization of effect size mixtures</span></span>
<span id="cb3-2"><a href=""></a><span class="fu">set.seed</span>(<span class="dv">789</span>)</span>
<span id="cb3-3"><a href=""></a></span>
<span id="cb3-4"><a href=""></a><span class="co"># Parameters</span></span>
<span id="cb3-5"><a href=""></a>n_variants <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb3-6"><a href=""></a>pi0 <span class="ot">&lt;-</span> <span class="fl">0.95</span>  <span class="co"># Proportion of null effects</span></span>
<span id="cb3-7"><a href=""></a></span>
<span id="cb3-8"><a href=""></a><span class="co"># Generate true effects</span></span>
<span id="cb3-9"><a href=""></a>is_null <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_variants, <span class="dv">1</span>, pi0)</span>
<span id="cb3-10"><a href=""></a>true_effects <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, n_variants)</span>
<span id="cb3-11"><a href=""></a>true_effects[is_null <span class="sc">==</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fu">sum</span>(is_null <span class="sc">==</span> <span class="dv">0</span>), <span class="dv">0</span>, <span class="fl">0.5</span>)</span>
<span id="cb3-12"><a href=""></a></span>
<span id="cb3-13"><a href=""></a><span class="co"># Add noise to create observed effects</span></span>
<span id="cb3-14"><a href=""></a>observed_effects <span class="ot">&lt;-</span> true_effects <span class="sc">+</span> <span class="fu">rnorm</span>(n_variants, <span class="dv">0</span>, <span class="fl">0.2</span>)</span>
<span id="cb3-15"><a href=""></a></span>
<span id="cb3-16"><a href=""></a><span class="co"># Create data frame for plotting</span></span>
<span id="cb3-17"><a href=""></a>effect_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb3-18"><a href=""></a>  <span class="at">Variant =</span> <span class="dv">1</span><span class="sc">:</span>n_variants,</span>
<span id="cb3-19"><a href=""></a>  <span class="at">TrueEffect =</span> true_effects,</span>
<span id="cb3-20"><a href=""></a>  <span class="at">ObservedEffect =</span> observed_effects,</span>
<span id="cb3-21"><a href=""></a>  <span class="at">IsNull =</span> <span class="fu">factor</span>(is_null)</span>
<span id="cb3-22"><a href=""></a>)</span>
<span id="cb3-23"><a href=""></a></span>
<span id="cb3-24"><a href=""></a><span class="co"># Plot</span></span>
<span id="cb3-25"><a href=""></a><span class="fu">ggplot</span>(effect_df, <span class="fu">aes</span>(<span class="at">x =</span> ObservedEffect, <span class="at">fill =</span> IsNull)) <span class="sc">+</span></span>
<span id="cb3-26"><a href=""></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">40</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">position =</span> <span class="st">"identity"</span>) <span class="sc">+</span></span>
<span id="cb3-27"><a href=""></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"gray70"</span>), </span>
<span id="cb3-28"><a href=""></a>                   <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Causal"</span>, <span class="st">"Null"</span>),</span>
<span id="cb3-29"><a href=""></a>                   <span class="at">name =</span> <span class="st">"Variant Type"</span>) <span class="sc">+</span></span>
<span id="cb3-30"><a href=""></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Mixture of Effect Sizes in GWAS"</span>,</span>
<span id="cb3-31"><a href=""></a>       <span class="at">subtitle =</span> <span class="st">"Most variants have no effect (null)"</span>,</span>
<span id="cb3-32"><a href=""></a>       <span class="at">x =</span> <span class="st">"Observed Effect Size"</span>, </span>
<span id="cb3-33"><a href=""></a>       <span class="at">y =</span> <span class="st">"Count"</span>) <span class="sc">+</span></span>
<span id="cb3-34"><a href=""></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb3-35"><a href=""></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-19-1.png" width="960" class="r-stretch"></section>
<section id="multivariate-normal-mixtures-the-mash-approach" class="slide level2">
<h2>Multivariate Normal Mixtures: The mash Approach</h2>
<p><strong>Key idea</strong>: Share information across related conditions</p>
<p><strong>Mathematical model</strong>:<br>
- <span class="math inline">\(\hat{\beta}_j \sim N(\beta_j, S_j)\)</span> (observed effects)<br>
- <span class="math inline">\(\beta_j \sim \sum_{k=1}^K \pi_k N(0, U_k)\)</span> (true effects)</p>
</section>
<section class="slide level2">

<p><strong>Covariance matrices</strong> <span class="math inline">\(U_k\)</span> capture patterns:<br>
- Shared effects across all conditions<br>
- Condition-specific effects<br>
- Structured correlation patterns<br>
- Data-driven patterns</p>
<p><strong>Benefits</strong>:<br>
- Improves effect estimation through sharing<br>
- Discovers patterns of effect heterogeneity<br>
- Controls false discovery rate<br>
- Provides interpretable multivariate posteriors</p>
</section>
<section id="types-of-shared-effects" class="slide level2">
<h2>Types of shared effects</h2>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href=""></a><span class="co"># Create a visualization of multivariate effects</span></span>
<span id="cb4-2"><a href=""></a><span class="fu">set.seed</span>(<span class="dv">345</span>)</span>
<span id="cb4-3"><a href=""></a></span>
<span id="cb4-4"><a href=""></a><span class="co"># Parameters</span></span>
<span id="cb4-5"><a href=""></a>n_effects <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb4-6"><a href=""></a>n_conditions <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb4-7"><a href=""></a></span>
<span id="cb4-8"><a href=""></a><span class="co"># Create different effect patterns</span></span>
<span id="cb4-9"><a href=""></a>patterns <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb4-10"><a href=""></a>  <span class="st">"Shared"</span> <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span>, n_conditions),</span>
<span id="cb4-11"><a href=""></a>  <span class="st">"Condition1"</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb4-12"><a href=""></a>  <span class="st">"Condition2"</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb4-13"><a href=""></a>  <span class="st">"Conditions1&amp;2"</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb4-14"><a href=""></a>  <span class="st">"Conditions3&amp;4"</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb4-15"><a href=""></a>)</span>
<span id="cb4-16"><a href=""></a></span>
<span id="cb4-17"><a href=""></a><span class="co"># Assign effects to patterns</span></span>
<span id="cb4-18"><a href=""></a>n_per_pattern <span class="ot">&lt;-</span> n_effects <span class="sc">/</span> <span class="fu">length</span>(patterns)</span>
<span id="cb4-19"><a href=""></a>true_effects <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> n_effects, <span class="at">ncol =</span> n_conditions)</span>
<span id="cb4-20"><a href=""></a><span class="fu">colnames</span>(true_effects) <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"Condition"</span>, <span class="dv">1</span><span class="sc">:</span>n_conditions)</span>
<span id="cb4-21"><a href=""></a></span>
<span id="cb4-22"><a href=""></a>current_idx <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb4-23"><a href=""></a><span class="cf">for</span> (p <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(patterns)) {</span>
<span id="cb4-24"><a href=""></a>  pattern_name <span class="ot">&lt;-</span> <span class="fu">names</span>(patterns)[p]</span>
<span id="cb4-25"><a href=""></a>  pattern <span class="ot">&lt;-</span> patterns[[p]]</span>
<span id="cb4-26"><a href=""></a>  </span>
<span id="cb4-27"><a href=""></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_per_pattern) {</span>
<span id="cb4-28"><a href=""></a>    effect_size <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="fl">0.5</span>)</span>
<span id="cb4-29"><a href=""></a>    true_effects[current_idx, ] <span class="ot">&lt;-</span> pattern <span class="sc">*</span> effect_size</span>
<span id="cb4-30"><a href=""></a>    current_idx <span class="ot">&lt;-</span> current_idx <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb4-31"><a href=""></a>  }</span>
<span id="cb4-32"><a href=""></a>}</span>
<span id="cb4-33"><a href=""></a></span>
<span id="cb4-34"><a href=""></a><span class="co"># Add noise to create observed effects</span></span>
<span id="cb4-35"><a href=""></a>observed_effects <span class="ot">&lt;-</span> true_effects <span class="sc">+</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n_effects <span class="sc">*</span> n_conditions, <span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb4-36"><a href=""></a>                                        <span class="at">nrow =</span> n_effects)</span>
<span id="cb4-37"><a href=""></a></span>
<span id="cb4-38"><a href=""></a><span class="co"># Select a few examples for visualization</span></span>
<span id="cb4-39"><a href=""></a>example_indices <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">45</span>, <span class="dv">85</span>, <span class="dv">125</span>, <span class="dv">165</span>)  <span class="co"># One from each pattern</span></span>
<span id="cb4-40"><a href=""></a>example_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb4-41"><a href=""></a>  <span class="at">Effect =</span> <span class="fu">rep</span>(<span class="fu">paste0</span>(<span class="st">"Effect"</span>, example_indices), <span class="at">each =</span> n_conditions),</span>
<span id="cb4-42"><a href=""></a>  <span class="at">Condition =</span> <span class="fu">rep</span>(<span class="fu">paste0</span>(<span class="st">"Condition"</span>, <span class="dv">1</span><span class="sc">:</span>n_conditions), <span class="at">times =</span> <span class="fu">length</span>(example_indices)),</span>
<span id="cb4-43"><a href=""></a>  <span class="at">TrueEffect =</span> <span class="fu">c</span>(<span class="fu">t</span>(true_effects[example_indices, ])),</span>
<span id="cb4-44"><a href=""></a>  <span class="at">ObservedEffect =</span> <span class="fu">c</span>(<span class="fu">t</span>(observed_effects[example_indices, ]))</span>
<span id="cb4-45"><a href=""></a>)</span>
<span id="cb4-46"><a href=""></a></span>
<span id="cb4-47"><a href=""></a><span class="co"># Reshape for plotting</span></span>
<span id="cb4-48"><a href=""></a>example_long <span class="ot">&lt;-</span> reshape2<span class="sc">::</span><span class="fu">melt</span>(example_data, </span>
<span id="cb4-49"><a href=""></a>                             <span class="at">id.vars =</span> <span class="fu">c</span>(<span class="st">"Effect"</span>, <span class="st">"Condition"</span>),</span>
<span id="cb4-50"><a href=""></a>                             <span class="at">variable.name =</span> <span class="st">"EffectType"</span>,</span>
<span id="cb4-51"><a href=""></a>                             <span class="at">value.name =</span> <span class="st">"Value"</span>)</span>
<span id="cb4-52"><a href=""></a></span>
<span id="cb4-53"><a href=""></a><span class="co"># Create plot</span></span>
<span id="cb4-54"><a href=""></a><span class="fu">ggplot</span>(example_long, <span class="fu">aes</span>(<span class="at">x =</span> Condition, <span class="at">y =</span> Value, <span class="at">color =</span> EffectType, <span class="at">group =</span> EffectType)) <span class="sc">+</span></span>
<span id="cb4-55"><a href=""></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb4-56"><a href=""></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb4-57"><a href=""></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> Effect, <span class="at">ncol =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb4-58"><a href=""></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"TrueEffect"</span> <span class="ot">=</span> <span class="st">"blue"</span>, <span class="st">"ObservedEffect"</span> <span class="ot">=</span> <span class="st">"red"</span>),</span>
<span id="cb4-59"><a href=""></a>                    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"True Effect"</span>, <span class="st">"Observed Effect"</span>)) <span class="sc">+</span></span>
<span id="cb4-60"><a href=""></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Multivariate Effect Patterns"</span>,</span>
<span id="cb4-61"><a href=""></a>       <span class="at">subtitle =</span> <span class="st">"mash identifies and leverages these patterns"</span>,</span>
<span id="cb4-62"><a href=""></a>       <span class="at">x =</span> <span class="st">""</span>, </span>
<span id="cb4-63"><a href=""></a>       <span class="at">y =</span> <span class="st">"Effect Size"</span>,</span>
<span id="cb4-64"><a href=""></a>       <span class="at">color =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb4-65"><a href=""></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>

</div>
<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-20-1.png" width="960" class="r-stretch"></section>
<section id="bayesian-meta-analysis-the-mathematical-framework" class="slide level2">
<h2>4. Bayesian Meta-Analysis: The Mathematical Framework</h2>
<p><strong>Problem</strong>: Combine evidence across heterogeneous studies</p>
<p><strong>Model formulation</strong>:<br>
- Let <span class="math inline">\(y_i\)</span> be the observed effect in study <span class="math inline">\(i\)</span><br>
- Let <span class="math inline">\(\sigma_i^2\)</span> be the variance (often known from standard error)<br>
- Let <span class="math inline">\(\theta_i\)</span> be the true effect in study <span class="math inline">\(i\)</span></p>
<p><strong>Hierarchical model</strong>:<br>
<span class="math inline">\(y_i | \theta_i, \sigma_i^2 \sim N(\theta_i, \sigma_i^2)\)</span><br>
<span class="math inline">\(\theta_i | \mu, \tau^2 \sim N(\mu, \tau^2)\)</span><br>
<span class="math inline">\(\mu \sim N(\mu_0, \sigma_0^2)\)</span><br>
<span class="math inline">\(\tau^2 \sim \text{InvGamma}(a, b)\)</span></p>
<p>Where:<br>
- <span class="math inline">\(\mu\)</span> is the overall mean effect<br>
- <span class="math inline">\(\tau^2\)</span> is the between-study heterogeneity<br>
- <span class="math inline">\(\mu_0, \sigma_0^2, a, b\)</span> are hyperparameters<br>
</p>
</section>
<section class="slide level2">

<p><strong>Key advantages</strong>:<br>
- Naturally accounts for heterogeneity<br>
- Uncertainty in all parameters<br>
- Shrinkage of extreme estimates toward the mean<br>
- Robust to outliers with appropriate priors</p>
</section>
<section id="bayesian-meta-analysis-visualization" class="slide level2">
<h2>Bayesian Meta-Analysis: Visualization</h2>
<p><strong>Traditional approaches</strong>:<br>
- Fixed effects (assumes same effect size)<br>
- Random effects (allows variation in effect size)<br>
- Often sensitive to outliers</p>
<p><strong>Bayesian advantages</strong>:<br>
- Full posterior distribution for all parameters<br>
- Can incorporate informative priors<br>
- Naturally handles small studies (shrinkage)<br>
- Can model outliers explicitly<br>
- Direct probability statements about effects</p>
<p><strong>Example interpretation</strong>:<br>
- Posterior probability of benefit = 98%<br>
- 95% credible interval for effect size: [0.1, 0.5]<br>
- 90% probability heterogeneity is moderate to high</p>
</section>
<section id="visualization" class="slide level2">
<h2>Visualization</h2>

<img data-src="mpg6_files/figure-revealjs/unnamed-chunk-21-1.png" width="960" class="r-stretch"></section>
<section id="practical-recommendations-for-bayesian-genomics" class="slide level2">
<h2>Practical Recommendations for Bayesian Genomics</h2>
<ol type="1">
<li><strong>Start with informative priors when possible</strong>
<ul>
<li>Use previous studies<br>
</li>
<li>Incorporate functional annotations<br>
</li>
<li>Consider evolutionary constraints</li>
</ul></li>
<li><strong>Report posterior probabilities, not just p-values</strong>
<ul>
<li><span class="math inline">\(P(\text{association} | \text{data})\)</span> is more interpretable than <span class="math inline">\(P(\text{data} | \text{no association})\)</span><br>
</li>
<li>Provides direct probability statements about hypotheses</li>
</ul></li>
<li><strong>Use conjugate models for computational efficiency</strong>
<ul>
<li>Beta-Binomial for allele frequencies<br>
</li>
<li>Dirichlet-Multinomial for haplotype frequencies<br>
</li>
<li>Normal-Normal for quantitative traits</li>
</ul></li>
<li><strong>Consider mixture models for complex data</strong>
<ul>
<li>Population structure<br>
</li>
<li>Heterogeneous effect sizes<br>
</li>
<li>Multiple causal variants</li>
</ul></li>
<li><strong>Apply decision theory for optimal designs</strong>
<ul>
<li>Balance false positives and false negatives<br>
</li>
<li>Consider costs of follow-up studies<br>
</li>
<li>Optimize sample allocation</li>
</ul></li>
</ol>
</section>
<section id="summary-when-to-use-bayesian-methods" class="slide level2">
<h2>Summary: When to Use Bayesian Methods</h2>
<table class="caption-top">
<colgroup>
<col style="width: 26%">
<col style="width: 33%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Problem</th>
<th>Bayesian Approach</th>
<th>Advantage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Multiple testing</td>
<td>Posterior probabilities</td>
<td>Direct interpretation, no arbitrary thresholds</td>
</tr>
<tr class="even">
<td>Sparse effects</td>
<td>Mixture priors</td>
<td>Better power, natural sparsity</td>
</tr>
<tr class="odd">
<td>Heterogeneous effects</td>
<td>Hierarchical models</td>
<td>Borrows strength across contexts</td>
</tr>
<tr class="even">
<td>Sequential data</td>
<td>Adaptive designs</td>
<td>Efficiency, early stopping</td>
</tr>
<tr class="odd">
<td>Prior knowledge integration</td>
<td>Informative priors</td>
<td>Improved accuracy, reduced sample size</td>
</tr>
<tr class="even">
<td>Complex dependencies</td>
<td>Bayesian networks</td>
<td>Causal inference, missing data handling</td>
</tr>
</tbody>
</table>
</section>
<section id="resources-for-bayesian-genomics" class="slide level2">
<h2>Resources for Bayesian Genomics</h2>
<p><strong>Software</strong>:<br>
- <strong>R packages</strong>: <code>rstan</code>, <code>brms</code>, <code>mashr</code>, ‘’ <code>BGLR</code>, <code>INLA</code><br>
- <strong>Python</strong>: <code>PyMC3</code>, <code>Stan</code>, <code>Edward</code><br>
- <strong>Specialized</strong>: <code>STRUCTURE</code>, <code>ADMIXTURE</code>, <code>SNPTEST</code></p>
<p><strong>Books</strong>:<br>
- “Bayesian Data Analysis” by Gelman et al.<br>
– “Understanding Uncertainty”, by David Lindley &nbsp; – “The Art of Statistics” David Spiegelhalter<br>
– “Bayesian Approaches to Clinical Trials” David Spiegelhalter<br>
– “Elements of Statistical Learning” Hastie, Tibshirani et al<br>
– “Statistical Rethinking” by McElreath<br>
</p>
</section>
<section id="online-resources" class="slide level2">
<h2><strong>Online Resources</strong>:</h2>
<ul>
<li><a href="https://stephenslab.github.io/fiveMinuteStats/">Five Minute Stats</a><br>
</li>
<li><a href="https://mc-stan.org/users/documentation/">Stan User Guide</a><br>
</li>
<li>ME! surbut@mgh.harvard.edu</li>
</ul>
</section>
<section id="questions" class="slide level2">
<h2>Questions?</h2>
<p>Thank you!!</p>
<p>Where would I be without:</p>
<ul>
<li><strong>Pradeep Natarajan, MD MMSc</strong></li>
<li><strong>Sasha Gusev, PhD</strong></li>
<li><strong>Giovanni Parmigiani, PhD</strong></li>
<li><strong>Matthew Stephens, PhD</strong></li>
</ul>
<div class="quarto-auto-generated-content">
<div class="footer footer-default">

</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="mpg6_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="mpg6_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="mpg6_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="mpg6_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="mpg6_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="mpg6_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="mpg6_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="mpg6_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="mpg6_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="mpg6_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>