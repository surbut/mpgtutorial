---
title: "Aladynoulli: Borrowing Information to Predict Disease"
subtitle: "A Statistical Journey in Medicine"
author: "Sarah Urbut, MD PhD and Giovanni Parmigiani, PhD"
format: 
  revealjs:
    theme: simple
    transition: slide
    slide-number: true
editor: 
  markdown: 
    wrap: 72
---

## My Journey: Bridging Multiple Worlds

::::: columns
::: {.column width="60%"}
-   Cardiologist, scientist, geneticist, and statistician ... confused
-   PhD focused on **mixture models**: like me?
-   Medicine and science enhance our understanding of disease
-   Combining statistical expertise with clinical experience
-   Came to Boston ... Met the best mentors of all time!
:::

::: {.column width="40%"}
![](aladynoulli-diverse-diagnoses.svg)
:::
:::::

::: notes
Like many applicants today, I’m fortunate to bridge multiple
worlds—cardiologist, scientist, geneticist, and statistician. My PhD in
statistics focused on mixture models, elegant frameworks for combining
different distributions to describe natural phenomena—much like how
medicine and science enhance our understanding of disease. One of my
first consults as a cardiology fellow revealed a paradox that struck me
as a statistician: A 38-year-old with clear signs and symptoms of an MI,
wouldn’t have qualified for primary prevention just a day earlier due to
our reliance on short-term and narrowly defined risk. This highlighted a
fundamental flaw: current models fail to capture how disease evolves
dynamically atop a genetic background. To both predict and understand,
we need to consider past, present, and future. Patients interact with
multiple specialties in their lifetime, revealing patterns across
diseases and time. Driven by clinical urgency yet informed by
statistical intuition, I set out to build a model from the groud up.
:::

## The Statistical Paradox in Medicine

::::: columns
::: {.column width="60%"}
-   One of my first consults as a cardiology fellow revealed a
    **paradox**:
-   A 38-year-old with clear signs of a heart attack
-   Yet just a day earlier, they wouldn't have qualified for prevention
-   Why? Our reliance on **short-term and narrowly defined risk**
-   A fundamental flaw: **current models fail to capture how disease
    evolves dynamically atop a genetic background**
:::

::: {.column width="40%"}
![A pager - the doctor's ball and chain](pager.svg)
:::
:::::

## The Challenge

::::: columns
:::: {.column width="100%"}
People develop multiple diseases over their lifetime, but:

-   Diseases don't occur in isolation
-   Comorbidities follow patterns, but these vary by individual
-   Genetics influences these patterns (but isn't destiny)
-   Standard approaches miss the dynamic nature of these relationships

::: notes
to both predict and understnad: how do we consider past present future
:::
::::
:::::

::: notes
Our problem exists in three dimensions: time, disease, and individual.
Our data consists of updated EHR diagnoses across over 350 diseases and
germline genomics,
:::

## What Are "Latent Variables"?

::::: columns
::: {.column width="60%"}
-   Things we can't directly observe
-   Must be inferred from what we can measure
-   Examples in everyday life:
    -   Underlying population structure
    -   Happiness (measured by behaviors)
    -   Underlying patterns (measured by symptoms and test results)
:::

::: {.column width="40%"}
![](latent-variable-diagram.svg)
:::
:::::

::: notes
We introduce and define signatures as latent patterns of disease
co-occurrence that vary in time at a population level. These signatures
are learned from the data in an unsupervised way, providing targets for
both discovery and prediction.
:::

## A Simple Medical Example

:::: columns
::: {.column width="100%"}
```         
Observable:               Hidden:                  Observable:
                          _________
Fever                    |         |
                   -----> DISEASE  |------> Lab Values  
Cough               |    |_________|    |
                    |                   |
Pain  --------------                    -------> Imaging Findings
```

The disease is a **latent variable** we infer from observable symptoms
and test results
:::
::::




## Example from Population Genetics

- You observe genotypes across 1000s of SNPs (high-dimensional, noisy, correlated)
- You don't observe the true "latent" coordinates 
- PCA finds directions of maximum variation
- Because alleles change gradually over geography (e.g., North-South, East-West in Europe), the leading PCs reflect these geographic gradients

::: {.callout}
PCA is recovering an unobserved, lower-dimensional latent structure: the ancestry and geography that shaped the genotypes.
:::

::: {.notes}
The latent variable structure that PCA is uncovering is the underlying population structure — specifically, the geographic ancestry of the individuals. In our simulation, that's their location on the fake "map" (their x_coord and y_coord), and in real genetics, it corresponds to shared ancestry patterns shaped by migration, drift, admixture, etc.
:::

## Real Data: Genotype Heatmap {.smaller}

```{r setup, include=FALSE}
# This chunk sets global options
knitr::opts_chunk$set(
  echo = FALSE,       # Don't show code
  message = FALSE,    # Don't show messages
  warning = FALSE,    # Don't show warnings
  fig.align = "center"
)
```

```{r load_data, include=FALSE}
# Load packages
library(SNPRelate)
library(pheatmap)
library(ggplot2)

# 1. Load example GDS file
gds.fn <- snpgdsExampleFileName()
genofile <- snpgdsOpen(gds.fn)

# 2. Get sample information
sample.id <- read.gdsn(index.gdsn(genofile, "sample.id"))
pop_code <- read.gdsn(index.gdsn(genofile, "sample.annot/pop.group"))

# 3. SNP pruning (light pruning for independent SNPs)
set.seed(100)
snpset <- snpgdsLDpruning(genofile, sample.id = sample.id, ld.threshold = 0.2)
snpset.id <- unlist(snpset)

# 4. Get genotype matrix for heatmap
geno <- snpgdsGetGeno(genofile, sample.id = sample.id, snp.id = snpset.id)
```

```{r genotype_heatmap}
# 5. Make heatmap - this will display
pheatmap(geno,
         cluster_rows = TRUE, cluster_cols = TRUE,
         show_rownames = FALSE, show_colnames = FALSE,
         main = "Genotype Heatmap (Multiple Populations)")
```

## Making Sense of It All: PCA Analysis

```{r pca_analysis, include=FALSE}
# 6. PCA analysis
pca <- snpgdsPCA(genofile, sample.id = sample.id, snp.id = snpset.id, num.thread = 2)

# 7. Prepare PCA plot data
pca_df <- data.frame(
  sample.id = pca$sample.id,
  PC1 = pca$eigenvect[,1],
  PC2 = pca$eigenvect[,2],
  Population = factor(pop_code[match(pca$sample.id, sample.id)])
)
```

```{r pca_plot}
# 8. Plot PCA with ancestry names as color - this will display
ggplot(pca_df, aes(x = PC1, y = PC2, color = Population)) +
  geom_point(size = 2, alpha = 0.8) +
  theme_minimal() +
  labs(title = "PCA of 1000 Genomes: Colored by Population",
       x = "PC1", y = "PC2", color = "Population") +
  scale_color_brewer(palette = "Set1")
```

```{r cleanup, include=FALSE}
# 9. Close GDS file
snpgdsClose(genofile)
```

## Key Insights

- PCA effectively clusters individuals by their genetic ancestry
- The first two principal components often correspond to major geographic patterns
- This dimensionality reduction technique reveals population structure that wasn't directly observed
- Each dot in the PCA plot represents an individual, clustered by their genetic similarity
- Different colors represent different population groups


## Understanding Latent Variables

![](images/pc-comparison-diagram.svg){width="600"}

::: notes
When two (or more) biomarkers are highly correlated, they contain
partially redundant information. Find the direction that maximizes
variation, which often means combining information from both markers,
resolving more differences than either alone. This is why these
statistical techniques are so powerful for medical applications. Rather
than looking at dozens of individual biomarkers in isolation, you can
create composite scores that capture more of the underlying biological
signal (like cardiac damage) Reduce noise by combining multiple
measurements and create better separation between patients with
different disease severity this concept extends beautifully to
time-varying data, binary outcomes, and the complex patterns of
comorbidities with Aladynoulli model!
:::

## Correlated biomarkers

Troponin and CK-MB

![](latent-variable-simple.svg)

## Disease "Signatures"

We introduce and define **signatures** as:

-   **Latent patterns of disease co-occurrence that vary in time**
-   Learned from data in an unsupervised way
-   Example signatures:
    -   Cardiovascular (hypercholesterolemia → CAD → heart failure)
    -   Metabolic (diabetes, obesity, fatty liver)
    -   Neoplastic (various cancers, anemia)
-   Discovered through statistical methods, not predefined categories

::: notes
Within each signature, diseases appear with characteristic incidence and
timing. For example, our method learns an ischemic cardiovascular
signature, in which hypercholesterolemia → CAD → CHF. Through the magic
that is matrix decomposition, signatures reveal natural patterns but
require no prespecified guidance.
:::

## Disease "Signatures"

![](disease-signatures-diagram.svg)

## How Signatures Change Over Time

:::: columns
::: {.column width="100%"}
![Diseases don't all happen at once - they follow patterns over
time](cvdsig.svg)
:::
::::

## Patient Trajectories Vary

::::: columns
::: {.column width="60%"}
**Patients don't sit still** - their signature profiles change over
time:

**Example patient journey:** - Rheumatologic diagnoses at age 30 -
Premature coronary artery disease at age 40 - Increased neoplastic risk
by age 50

This story is distinct from other patients, **revealing heterogeneity
underlying a shared phenotype**
:::

::: {.column width="40%"}
![](patient-trajectory-diagram.svg)
:::
:::::

::: notes
But patients don’t sit still – the relative loading or importance of a
signature to a patient depends on when the question is asked. Example:
Our patient may have rheumatologic diagnoses at 30, develop premature
CAD at 40, and by 50, increased neoplastic risk. This story is distinct
from another patient revealing heterogeneity underlying a shared
phenotype. turning this patient story into math can help us formalize
the discussion into a solvable problem with a few key parameters
:::

## Borrowing Information

::::: columns
::: {.column width="60%"}
**Key Statistical Insight:**

We can "borrow information" from similar patients to make better
predictions

-   If we see Patient A with pattern X develop disease Y
-   And Patient B shows early signs of pattern X
-   We can better predict B's risk of disease Y
:::

::: {.column width="40%"}
![Connecting the dots across patients](histories.svg)
:::
:::::

## The Bayesian Approach

:::: columns
::: {.column width="100%"}
Mathematical way to update our beliefs as new information arrives:

$$\text{Updated Belief} \propto \text{Prior Knowledge} \times \text{New Data}$$

In practical terms:

**Start with what we know about disease patterns in general**

**Update based on this specific patient's data**

**Continually refine as more information comes in**
:::
::::

## A Simple Bayesian Example

Predicting heart attack risk:

1.  **Prior**: 5% of people with high blood pressure have heart attacks
2.  **New Data**: Our patient has chest pain
3.  **Updated Belief**: Risk is now 15% given both factors

This is "borrowing information" from population studies to help with
individual prediction.

## The Mathematical Model (Simplified)

Turning patient stories into math helps us formalize the problem:

-   **ϕ (phi)** - Time-varying disease signatures
    -   How different diseases evolve over time within a signature
    -   Centered around population incidence
-   **λ (lambda)** - Individual's time-varying signature loading
    -   Anchored on germline genetic predisposition
    -   Shows which signatures are important for a specific person

::: notes
ϕ (phi) represents the time varying signatures, where each signature
demonstrates how different diseases evolve over time, centered around
population incidence (mu) and a term relating the importance of the
signature to the disease (psid) λ represents an individual’s time
varying loading, anchored on their germline genetic predisposition Both
evolve smoothly over time as captured in their covariance matrix, which
helps us borrow information across years.
:::

## The Mathematical Model (Simplified)

![](bayesian-model-diagram.svg)

## The Bayesian Magic

::::: columns
::: {.column width="60%"}
Our approach works because:

1.  We start with prior beliefs (based on population patterns)
2.  **Each new diagnosis refines our model parameters in real time**
3.  We integrate prior knowledge with patient-specific data
4.  The past informs the present, and the present becomes the past to
    inform the future
:::

::: {.column width="40%"}
![](bayesian-updating-diagram.svg)
:::
:::::

::: notes
Before encountering data, these serve as our prior beliefs And herein
lies the Bayesian magic —each new diagnosis refines these key parameters
in real time, integrating prior knowledge with patient-specific data
(point to bayes rule) we then combine these parameters across
signatures, generating disease probabilities, to also help predict the
future. This is a key innovation that separates the Aladynoulli
approach, and stems from its Bernoulli parameterization Returning to our
pt, this feature could mean the difference between prevention and
emergency intervention"
:::

## Four key innovations:

1.  **Bridges discovery and prediction**
2.  **Disease signatures evolve over time and across diseases**
3.  **Anchoring in genomics** produces biologically meaningful
    parameters
4.  **Bayesian updating adapts estimates in real time**

::: notes
The novelty in our approach parallels our patient’s walk in 4 key ways:
\*First, our model bridges discovery and prediction, by discovering
latent disease signatures that also combine to form individualized
predictions. Second, our disease signatures evolve over time and across
disease, expanding the dimension of shared biology. Third, anchoring
individual loadings in genomics ensures that our model produces
biologically informed parameters rather than ML artifacts, which enables
targeted precision treatment strategies. And finally, Bayesian updating
adapts estimates in real time, jointly refining our understanding of the
population and the individual. Our 38-year-old patient’s past informs
the present, and the present becomes the past to inform the future.
:::

## Why This Matters

::::: columns
::: {.column width="40%"}
-   Earlier detection of disease
-   More personalized prevention strategies
-   Better understanding of disease mechanisms
-   Identifying new subtypes of diseases
-   Improving clinical trials by targeting the right patients
:::

::: {.column width="60%"}
![Better prevention and prediction](fig5.svg)
:::
:::::

## Case Study: Early Heart Disease

:::: columns
::: {.column width="100%"}
![A patient's signature profile can predict risk years before disease
appears](figure3_patient_example_2.svg)
:::
::::

## Why This Work Matters

:::: columns
::: {.column width="100%"}
This work is the essence of translational medicine:

-   Bridges basic, methodologic, and clinical science
-   Requires both math and biology appreciation
-   Transcends single-discipline medicine
-   Transforms how we predict, prevent, and understand disease
    progression

What statistics has taught me: - Complex systems can be modeled but
require careful assumptions - Uncertainty should be embraced, not
ignored - Borrowing information is powerful but must be done carefully -
The best models combine mathematical elegance with real-world
knowledge - Clinical intuition + statistical rigor = better medicine
:::
::::

## Resources & Questions

:::: columns
::: {.column width="60%"}
-   Paper:
    [medrxiv.org/content/10.1101/2024.09.29.24314557V1](https://www.medrxiv.org/content/10.1101/2024.09.29.24314557V1)
-   Code:
    [github.com/surbut/Aladynoulli2](https://github.com/surbut/Aladynoulli2)
-   Interactive app:
    [Surbut.shinyapps.io/berndiffapp](https://Surbut.shinyapps.io/berndiffapp)
:::

## Thank You!

Statistics can help us understand health in ways that transform
medicine.

(And yes, it's worth learning for your Stat 102 class!)
::::
